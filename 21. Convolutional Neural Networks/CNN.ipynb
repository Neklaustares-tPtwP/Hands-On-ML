{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b817f781-4a48-47af-b18e-1b5a6ff281b4",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eaef9f-e43c-410e-b8b5-c87955843b14",
   "metadata": {},
   "source": [
    "## Buidling CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b79a81be-f953-4780-bc46-fe9bbff18146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa3808-a3d5-4b79-9176-faca9bf8ddac",
   "metadata": {},
   "source": [
    "#### Initialising CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e7aa9b-488b-41a8-a746-2f6a6979a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b94388-9806-4ca0-ab77-78604603d248",
   "metadata": {},
   "source": [
    "#### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de82611-e54f-4561-9988-bed33cde1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(filters = 32,kernel_size = (3, 3), \n",
    "                      input_shape = (64, 64, 3), activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432181b-d472-4202-b39d-0bdd5c92c2c9",
   "metadata": {},
   "source": [
    "#### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94173189-332a-4aba-a0f7-0838bd8d61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e1c1ef-e8ea-4917-b514-1d6d064f0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(filters = 32,kernel_size = (3, 3), activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2ad3fe-73e3-4750-ab59-0c7ea26223f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e4146-3b4e-4d72-bd2a-59ce65feb68e",
   "metadata": {},
   "source": [
    "#### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ed7d00-4426-4aea-b769-d291b73b4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f4543-f07b-4c1f-9ba4-be14c652bbc9",
   "metadata": {},
   "source": [
    "#### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c845d9e-0d84-4f21-bf17-22b1b381c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = \"relu\"))\n",
    "classifier.add(Dense(units = 1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b233d9-9a16-4f7d-8156-b4ee41a39586",
   "metadata": {},
   "source": [
    "#### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738351b2-f561-4a86-874e-762c1c10cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f267f-6839-422a-8011-300d34c4120b",
   "metadata": {},
   "source": [
    "## Fitting the CNN to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb02c585-3661-43b5-afbd-839add3874cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20ad482-22b1-438a-a0cd-01128f68f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dbf0a97-e228-4743-9fc4-af1c33a2d7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_dataset = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                    target_size=(64, 64),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1efddd8-33f3-4835-b17f-b52cb59e616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_dataset = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                                target_size=(64, 64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92a31f22-281e-43a2-8934-8ed88a403ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classifier.fit_generator(training_dataset,\\n                        steps_per_epoch=8000,\\n                        epochs=25,\\n                        validation_data=testing_dataset,\\n                        validation_steps=2000)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''classifier.fit_generator(training_dataset,\n",
    "                        steps_per_epoch=8000,\n",
    "                        epochs=25,\n",
    "                        validation_data=testing_dataset,\n",
    "                        validation_steps=2000)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5df7953e-d84e-45e9-8c2f-83b921a899f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.6816 - accuracy: 0.5651 - val_loss: 0.6950 - val_accuracy: 0.5530\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 0.6130 - accuracy: 0.6620 - val_loss: 0.5499 - val_accuracy: 0.7300\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.5508 - accuracy: 0.7201 - val_loss: 0.5328 - val_accuracy: 0.7265\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.5373 - accuracy: 0.7286 - val_loss: 0.5239 - val_accuracy: 0.7445\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.4952 - accuracy: 0.7569 - val_loss: 0.4979 - val_accuracy: 0.7655\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.4817 - accuracy: 0.7669 - val_loss: 0.5393 - val_accuracy: 0.7320\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.4694 - accuracy: 0.7764 - val_loss: 0.4648 - val_accuracy: 0.7910\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 26s 106ms/step - loss: 0.4508 - accuracy: 0.7881 - val_loss: 0.4696 - val_accuracy: 0.7820\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.4308 - accuracy: 0.7981 - val_loss: 0.4713 - val_accuracy: 0.7960\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.4278 - accuracy: 0.8065 - val_loss: 0.4778 - val_accuracy: 0.7815\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.4016 - accuracy: 0.8150 - val_loss: 0.5068 - val_accuracy: 0.7735\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.3882 - accuracy: 0.8216 - val_loss: 0.4830 - val_accuracy: 0.7960\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.3726 - accuracy: 0.8346 - val_loss: 0.4795 - val_accuracy: 0.7935\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.3602 - accuracy: 0.8407 - val_loss: 0.4609 - val_accuracy: 0.7955\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 27s 108ms/step - loss: 0.3503 - accuracy: 0.8425 - val_loss: 0.5702 - val_accuracy: 0.7860\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 0.3318 - accuracy: 0.8544 - val_loss: 0.4817 - val_accuracy: 0.8160\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.3260 - accuracy: 0.8558 - val_loss: 0.4779 - val_accuracy: 0.8080\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.3100 - accuracy: 0.8660 - val_loss: 0.5227 - val_accuracy: 0.7940\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.2864 - accuracy: 0.8773 - val_loss: 0.5272 - val_accuracy: 0.8015\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.2794 - accuracy: 0.8821 - val_loss: 0.5521 - val_accuracy: 0.7930\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.2679 - accuracy: 0.8879 - val_loss: 0.5138 - val_accuracy: 0.8045\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.2543 - accuracy: 0.8939 - val_loss: 0.5476 - val_accuracy: 0.7995\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.2345 - accuracy: 0.9034 - val_loss: 0.5406 - val_accuracy: 0.8050\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.2422 - accuracy: 0.8978 - val_loss: 0.5431 - val_accuracy: 0.8010\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.2190 - accuracy: 0.9101 - val_loss: 0.6000 - val_accuracy: 0.7865\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.2073 - accuracy: 0.9160 - val_loss: 0.5500 - val_accuracy: 0.8095\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.1906 - accuracy: 0.9270 - val_loss: 0.6535 - val_accuracy: 0.7910\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.1902 - accuracy: 0.9241 - val_loss: 0.6264 - val_accuracy: 0.8070\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.1640 - accuracy: 0.9342 - val_loss: 0.7079 - val_accuracy: 0.7935\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.1735 - accuracy: 0.9334 - val_loss: 0.6182 - val_accuracy: 0.8005\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.1670 - accuracy: 0.9367 - val_loss: 0.6301 - val_accuracy: 0.7990\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.1581 - accuracy: 0.9386 - val_loss: 0.6665 - val_accuracy: 0.8055\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.1538 - accuracy: 0.9381 - val_loss: 0.6827 - val_accuracy: 0.8025\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.1320 - accuracy: 0.9498 - val_loss: 0.7971 - val_accuracy: 0.7885\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.1358 - accuracy: 0.9498 - val_loss: 0.6478 - val_accuracy: 0.8035\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.1245 - accuracy: 0.9517 - val_loss: 0.7151 - val_accuracy: 0.7950\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.1241 - accuracy: 0.9519 - val_loss: 0.8814 - val_accuracy: 0.7750\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.1243 - accuracy: 0.9534 - val_loss: 0.7542 - val_accuracy: 0.8035\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.1247 - accuracy: 0.9536 - val_loss: 0.7565 - val_accuracy: 0.7965\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.1087 - accuracy: 0.9571 - val_loss: 0.7510 - val_accuracy: 0.8010\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.1067 - accuracy: 0.9581 - val_loss: 0.7825 - val_accuracy: 0.7915\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.1117 - accuracy: 0.9556 - val_loss: 0.7831 - val_accuracy: 0.7955\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.0978 - accuracy: 0.9639 - val_loss: 0.8146 - val_accuracy: 0.7990\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.0908 - accuracy: 0.9663 - val_loss: 0.8691 - val_accuracy: 0.7950\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 27s 107ms/step - loss: 0.0942 - accuracy: 0.9632 - val_loss: 0.8896 - val_accuracy: 0.7895\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0934 - accuracy: 0.9650 - val_loss: 0.8026 - val_accuracy: 0.8015\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.0842 - accuracy: 0.9689 - val_loss: 0.9425 - val_accuracy: 0.7845\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 0.0845 - accuracy: 0.9668 - val_loss: 0.9221 - val_accuracy: 0.7990\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.0871 - accuracy: 0.9681 - val_loss: 0.8044 - val_accuracy: 0.8070\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 0.0721 - accuracy: 0.9730 - val_loss: 0.8102 - val_accuracy: 0.8055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21c9e16b7f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x = training_dataset, validation_data = testing_dataset, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf279d01-ffd7-473b-8bf1-2e6cb3ae85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/test_image/germanshepherd.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_dataset.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4883cd44-8720-4553-848f-cb448d5098dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
